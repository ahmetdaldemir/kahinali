#!/usr/bin/env python3
"""
KAHÄ°N ULTIMA - KapsamlÄ± AI Model EÄŸitimi
TÃ¼m modelleri (LSTM, Random Forest, Gradient Boosting) eksiksiz eÄŸitir
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
import logging
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
import pickle
import gc
import joblib

# Deep Learning imports
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

warnings.filterwarnings('ignore')

# Proje kÃ¶k dizinini ekle
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.ai_model import AIModel
from modules.data_collector import DataCollector
from modules.technical_analysis import TechnicalAnalysis

# Logging ayarlarÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/complete_ai_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class CompleteAITraining:
    """KapsamlÄ± AI Model EÄŸitimi"""
    
    def __init__(self):
        self.logger = logger
        self.models_dir = 'models'
        os.makedirs(self.models_dir, exist_ok=True)
        
        # Model dosya yollarÄ±
        self.lstm_model_path = os.path.join(self.models_dir, 'lstm_model.h5')
        self.rf_model_path = os.path.join(self.models_dir, 'random_forest_model.pkl')
        self.gb_model_path = os.path.join(self.models_dir, 'gradient_boosting_model.pkl')
        self.ensemble_model_path = os.path.join(self.models_dir, 'ensemble_model.pkl')
        self.feature_cols_path = os.path.join(self.models_dir, 'feature_cols.pkl')
        self.scaler_path = os.path.join(self.models_dir, 'scaler.pkl')
        
    def prepare_training_data(self):
        """EÄŸitim verisini hazÄ±rla"""
        self.logger.info("ğŸ“Š EÄŸitim verisi hazÄ±rlanÄ±yor...")
        
        try:
            # Veri dosyasÄ±nÄ± kontrol et
            data_file = 'train_data_with_target.csv'
            if not os.path.exists(data_file):
                self.logger.error(f"Veri dosyasÄ± bulunamadÄ±: {data_file}")
                return None
            
            # Veriyi yÃ¼kle
            df = pd.read_csv(data_file)
            self.logger.info(f"Veri yÃ¼klendi: {df.shape}")
            
            # NaN deÄŸerleri temizle
            df = df.dropna()
            self.logger.info(f"NaN temizleme sonrasÄ±: {df.shape}")
            
            # Sonsuz deÄŸerleri temizle
            df = df.replace([np.inf, -np.inf], np.nan)
            df = df.dropna()
            self.logger.info(f"Sonsuz deÄŸer temizleme sonrasÄ±: {df.shape}")
            
            # Target kolonunu ayÄ±r
            if 'target' not in df.columns:
                self.logger.error("Target kolonu bulunamadÄ±!")
                return None
            
            X = df.drop(['target'], axis=1)
            y = df['target']
            
            # Feature listesini kaydet
            feature_cols = X.columns.tolist()
            joblib.dump(feature_cols, self.feature_cols_path)
            self.logger.info(f"Feature listesi kaydedildi: {len(feature_cols)} feature")
            
            # Train-test split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            # Scaler oluÅŸtur ve kaydet
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            joblib.dump(scaler, self.scaler_path)
            self.logger.info("Scaler kaydedildi")
            
            return {
                'X_train': X_train,
                'X_test': X_test,
                'y_train': y_train,
                'y_test': y_test,
                'X_train_scaled': X_train_scaled,
                'X_test_scaled': X_test_scaled,
                'feature_cols': feature_cols
            }
            
        except Exception as e:
            self.logger.error(f"Veri hazÄ±rlama hatasÄ±: {e}")
            return None
    
    def train_random_forest(self, data):
        """Random Forest modelini eÄŸit"""
        self.logger.info("ğŸŒ² Random Forest eÄŸitiliyor...")
        
        try:
            rf_model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            rf_model.fit(data['X_train'], data['y_train'])
            
            # Tahmin
            y_pred = rf_model.predict(data['X_test'])
            accuracy = accuracy_score(data['y_test'], y_pred)
            
            # Modeli kaydet
            joblib.dump(rf_model, self.rf_model_path)
            
            self.logger.info(f"âœ“ Random Forest eÄŸitildi - DoÄŸruluk: {accuracy:.4f}")
            return accuracy
            
        except Exception as e:
            self.logger.error(f"Random Forest eÄŸitim hatasÄ±: {e}")
            return None
    
    def train_gradient_boosting(self, data):
        """Gradient Boosting modelini eÄŸit"""
        self.logger.info("ğŸš€ Gradient Boosting eÄŸitiliyor...")
        
        try:
            gb_model = GradientBoostingClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
            
            gb_model.fit(data['X_train'], data['y_train'])
            
            # Tahmin
            y_pred = gb_model.predict(data['X_test'])
            accuracy = accuracy_score(data['y_test'], y_pred)
            
            # Modeli kaydet
            joblib.dump(gb_model, self.gb_model_path)
            
            self.logger.info(f"âœ“ Gradient Boosting eÄŸitildi - DoÄŸruluk: {accuracy:.4f}")
            return accuracy
            
        except Exception as e:
            self.logger.error(f"Gradient Boosting eÄŸitim hatasÄ±: {e}")
            return None
    
    def train_lstm(self, data):
        """LSTM modelini eÄŸit"""
        self.logger.info("ğŸ§  LSTM modeli eÄŸitiliyor...")
        
        try:
            # LSTM iÃ§in veriyi yeniden ÅŸekillendir
            X_train_lstm = data['X_train_scaled'].reshape((data['X_train_scaled'].shape[0], 1, data['X_train_scaled'].shape[1]))
            X_test_lstm = data['X_test_scaled'].reshape((data['X_test_scaled'].shape[0], 1, data['X_test_scaled'].shape[1]))
            
            # LSTM modeli oluÅŸtur
            lstm_model = Sequential([
                LSTM(128, return_sequences=True, input_shape=(1, data['X_train_scaled'].shape[1])),
                Dropout(0.2),
                LSTM(64, return_sequences=False),
                Dropout(0.2),
                Dense(32, activation='relu'),
                Dense(1, activation='sigmoid')
            ])
            
            # Modeli derle
            lstm_model.compile(
                optimizer=Adam(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy']
            )
            
            # Early stopping
            early_stopping = EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            )
            
            # Modeli eÄŸit
            history = lstm_model.fit(
                X_train_lstm, data['y_train'],
                validation_data=(X_test_lstm, data['y_test']),
                epochs=50,
                batch_size=32,
                callbacks=[early_stopping],
                verbose=1
            )
            
            # Tahmin
            y_pred_proba = lstm_model.predict(X_test_lstm)
            y_pred = (y_pred_proba > 0.5).astype(int)
            accuracy = accuracy_score(data['y_test'], y_pred)
            
            # Modeli kaydet
            lstm_model.save(self.lstm_model_path)
            
            self.logger.info(f"âœ“ LSTM modeli eÄŸitildi - DoÄŸruluk: {accuracy:.4f}")
            return accuracy
            
        except Exception as e:
            self.logger.error(f"LSTM eÄŸitim hatasÄ±: {e}")
            return None
    
    def create_ensemble(self, data):
        """Ensemble modeli oluÅŸtur"""
        self.logger.info("ğŸ¯ Ensemble modeli oluÅŸturuluyor...")
        
        try:
            # Modelleri yÃ¼kle
            rf_model = joblib.load(self.rf_model_path)
            gb_model = joblib.load(self.gb_model_path)
            lstm_model = tf.keras.models.load_model(self.lstm_model_path)
            
            # Ensemble tahminleri
            rf_pred = rf_model.predict_proba(data['X_test'])[:, 1]
            gb_pred = gb_model.predict_proba(data['X_test'])[:, 1]
            
            # LSTM tahmini
            X_test_lstm = data['X_test_scaled'].reshape((data['X_test_scaled'].shape[0], 1, data['X_test_scaled'].shape[1]))
            lstm_pred = lstm_model.predict(X_test_lstm).flatten()
            
            # AÄŸÄ±rlÄ±klÄ± ensemble
            ensemble_pred = (0.4 * rf_pred + 0.3 * gb_pred + 0.3 * lstm_pred)
            ensemble_pred_binary = (ensemble_pred > 0.5).astype(int)
            
            accuracy = accuracy_score(data['y_test'], ensemble_pred_binary)
            
            # Ensemble modeli kaydet
            ensemble_data = {
                'rf_model_path': self.rf_model_path,
                'gb_model_path': self.gb_model_path,
                'lstm_model_path': self.lstm_model_path,
                'weights': {'rf': 0.4, 'gb': 0.3, 'lstm': 0.3}
            }
            
            joblib.dump(ensemble_data, self.ensemble_model_path)
            
            self.logger.info(f"âœ“ Ensemble modeli oluÅŸturuldu - DoÄŸruluk: {accuracy:.4f}")
            return accuracy
            
        except Exception as e:
            self.logger.error(f"Ensemble oluÅŸturma hatasÄ±: {e}")
            return None
    
    def test_models(self):
        """TÃ¼m modelleri test et"""
        self.logger.info("ğŸ§ª Modeller test ediliyor...")
        
        try:
            # AI model modÃ¼lÃ¼nÃ¼ baÅŸlat
            ai_model = AIModel()
            
            # Test verisi al
            collector = DataCollector()
            df = collector.get_historical_data('BTC/USDT', '1h', 100)
            
            if df is None or df.empty:
                self.logger.error("Test verisi alÄ±namadÄ±")
                return False
            
            # Teknik analiz
            ta = TechnicalAnalysis()
            df_with_indicators = ta.calculate_all_indicators(df)
            
            if df_with_indicators is None or df_with_indicators.empty:
                self.logger.error("Teknik analiz baÅŸarÄ±sÄ±z")
                return False
            
            # AI tahmin
            result = ai_model.predict(df_with_indicators)
            
            if isinstance(result, tuple) and len(result) == 2:
                prediction, confidence = result
                if prediction is not None and confidence is not None:
                    self.logger.info(f"âœ“ AI tahmin baÅŸarÄ±lÄ±: {prediction:.4f}, GÃ¼ven: {confidence:.4f}")
                    return True
                else:
                    self.logger.error("AI tahmin baÅŸarÄ±sÄ±z")
                    return False
            else:
                self.logger.error(f"AI tahmin format hatasÄ±: {result}")
                return False
                
        except Exception as e:
            self.logger.error(f"Model test hatasÄ±: {e}")
            return False
    
    def run_complete_training(self):
        """KapsamlÄ± eÄŸitim sÃ¼recini Ã§alÄ±ÅŸtÄ±r"""
        self.logger.info("ğŸš€ KAPSAMLI AI MODEL EÄÄ°TÄ°MÄ° BAÅLATIYOR")
        self.logger.info("=" * 60)
        
        start_time = datetime.now()
        
        try:
            # 1. Veri hazÄ±rlama
            data = self.prepare_training_data()
            if data is None:
                return False
            
            # 2. Random Forest eÄŸitimi
            rf_accuracy = self.train_random_forest(data)
            if rf_accuracy is None:
                return False
            
            # 3. Gradient Boosting eÄŸitimi
            gb_accuracy = self.train_gradient_boosting(data)
            if gb_accuracy is None:
                return False
            
            # 4. LSTM eÄŸitimi
            lstm_accuracy = self.train_lstm(data)
            if lstm_accuracy is None:
                return False
            
            # 5. Ensemble oluÅŸturma
            ensemble_accuracy = self.create_ensemble(data)
            if ensemble_accuracy is None:
                return False
            
            # 6. Model testi
            test_success = self.test_models()
            
            # 7. SonuÃ§ raporu
            end_time = datetime.now()
            duration = end_time - start_time
            
            self.logger.info("\n" + "=" * 60)
            self.logger.info("ğŸ¯ EÄÄ°TÄ°M SONUÃ‡LARI")
            self.logger.info("=" * 60)
            self.logger.info(f"â±ï¸  SÃ¼re: {duration}")
            self.logger.info(f"ğŸŒ² Random Forest: {rf_accuracy:.4f}")
            self.logger.info(f"ğŸš€ Gradient Boosting: {gb_accuracy:.4f}")
            self.logger.info(f"ğŸ§  LSTM: {lstm_accuracy:.4f}")
            self.logger.info(f"ğŸ¯ Ensemble: {ensemble_accuracy:.4f}")
            self.logger.info(f"ğŸ§ª Test: {'âœ“ BaÅŸarÄ±lÄ±' if test_success else 'âŒ BaÅŸarÄ±sÄ±z'}")
            
            # Ortalama doÄŸruluk
            avg_accuracy = (rf_accuracy + gb_accuracy + lstm_accuracy) / 3
            self.logger.info(f"ğŸ“Š Ortalama DoÄŸruluk: {avg_accuracy:.4f}")
            
            if test_success:
                self.logger.info("ğŸ‰ KAPSAMLI EÄÄ°TÄ°M BAÅARIYLA TAMAMLANDI!")
                return True
            else:
                self.logger.error("âŒ Model testi baÅŸarÄ±sÄ±z!")
                return False
                
        except Exception as e:
            self.logger.error(f"EÄŸitim sÃ¼reci hatasÄ±: {e}")
            return False

def main():
    """Ana fonksiyon"""
    trainer = CompleteAITraining()
    success = trainer.run_complete_training()
    
    if success:
        print("\nâœ… KAPSAMLI AI EÄÄ°TÄ°MÄ° BAÅARIYLA TAMAMLANDI!")
        print("ğŸ“ Modeller 'models/' klasÃ¶rÃ¼nde kaydedildi")
        print("ğŸ§ª Sistem test edildi ve Ã§alÄ±ÅŸÄ±yor")
    else:
        print("\nâŒ EÄŸitim sÃ¼recinde hata oluÅŸtu!")
    
    return success

if __name__ == "__main__":
    main() 