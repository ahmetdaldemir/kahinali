#!/usr/bin/env python3
"""
KAHÄ°N ULTIMA - Hafif AI Model EÄŸitimi
Bellek sorunlarÄ±nÄ± Ã¶nlemek iÃ§in optimize edilmiÅŸ eÄŸitim scripti
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
import logging
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import pickle
import gc

warnings.filterwarnings('ignore')

# Proje kÃ¶k dizinini ekle
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.ai_model import AIModel
from modules.data_collector import DataCollector

# Logging ayarlarÄ±
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/lightweight_training.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def clean_infinite_values(df):
    """Sonsuz deÄŸerleri temizle"""
    logger.info("Sonsuz deÄŸerler temizleniyor...")
    
    # Sonsuz deÄŸerleri NaN'a Ã§evir
    df = df.replace([np.inf, -np.inf], np.nan)
    
    # NaN deÄŸerleri medyan ile doldur
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    for col in numeric_columns:
        if df[col].isnull().sum() > 0:
            median_val = df[col].median()
            df[col].fillna(median_val, inplace=True)
    
    logger.info(f"Temizleme sonrasÄ± veri boyutu: {df.shape}")
    return df

def prepare_training_data():
    """EÄŸitim verisini hazÄ±rla"""
    logger.info("=== HAFÄ°F AI MODEL EÄÄ°TÄ°MÄ° BAÅLADI ===")
    
    try:
        # Veri dosyasÄ±nÄ± kontrol et
        data_file = 'train_data_with_target.csv'
        if not os.path.exists(data_file):
            logger.error(f"Veri dosyasÄ± bulunamadÄ±: {data_file}")
            return None
        
        # Veriyi yÃ¼kle
        logger.info("EÄŸitim verisi yÃ¼kleniyor...")
        df = pd.read_csv(data_file)
        logger.info(f"Veri yÃ¼klendi: {df.shape}")
        
        # Label daÄŸÄ±lÄ±mÄ±nÄ± kontrol et
        if 'target' in df.columns:
            label_dist = df['target'].value_counts()
            logger.info(f"Label daÄŸÄ±lÄ±mÄ±: {dict(label_dist)}")
        
        # Sonsuz deÄŸerleri temizle
        df = clean_infinite_values(df)
        
        # Feature'larÄ± hazÄ±rla
        feature_columns = [col for col in df.columns if col not in ['target', 'timestamp', 'symbol']]
        logger.info(f"Feature sayÄ±sÄ±: {len(feature_columns)}")
        
        # Veriyi bÃ¶l
        X = df[feature_columns]
        y = df['target'] if 'target' in df.columns else None
        
        if y is None:
            logger.error("Target kolonu bulunamadÄ±")
            return None
        
        # Veriyi eÄŸitim ve test olarak bÃ¶l
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        logger.info(f"EÄŸitim seti: {X_train.shape}")
        logger.info(f"Test seti: {X_test.shape}")
        
        return X_train, X_test, y_train, y_test, feature_columns
        
    except Exception as e:
        logger.error(f"Veri hazÄ±rlama hatasÄ±: {e}")
        return None

def train_random_forest(X_train, X_test, y_train, y_test, feature_columns):
    """Random Forest modelini eÄŸit"""
    logger.info("Random Forest eÄŸitiliyor...")
    
    try:
        # Daha kÃ¼Ã§Ã¼k parametrelerle model oluÅŸtur
        rf_model = RandomForestClassifier(
            n_estimators=100,  # Daha az aÄŸaÃ§
            max_depth=10,       # Daha sÄ±ÄŸ aÄŸaÃ§lar
            min_samples_split=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=1  # Tek thread kullan
        )
        
        # Modeli eÄŸit
        rf_model.fit(X_train, y_train)
        
        # Tahmin yap
        y_pred = rf_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        logger.info(f"Random Forest doÄŸruluk: {accuracy:.4f}")
        
        # Modeli kaydet
        model_path = 'models/random_forest_model.pkl'
        with open(model_path, 'wb') as f:
            pickle.dump(rf_model, f)
        logger.info(f"Random Forest modeli kaydedildi: {model_path}")
        
        # Feature importance'larÄ± kaydet
        feature_importance = pd.DataFrame({
            'feature': feature_columns,
            'importance': rf_model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        importance_path = 'models/feature_importance.pkl'
        with open(importance_path, 'wb') as f:
            pickle.dump(feature_importance, f)
        logger.info(f"Feature importance kaydedildi: {importance_path}")
        
        return rf_model, accuracy
        
    except Exception as e:
        logger.error(f"Random Forest eÄŸitim hatasÄ±: {e}")
        return None, 0

def train_gradient_boosting(X_train, X_test, y_train, y_test, feature_columns):
    """Gradient Boosting modelini eÄŸit"""
    logger.info("Gradient Boosting eÄŸitiliyor...")
    
    try:
        from sklearn.ensemble import GradientBoostingClassifier
        
        # Daha kÃ¼Ã§Ã¼k parametrelerle model oluÅŸtur
        gb_model = GradientBoostingClassifier(
            n_estimators=50,    # Daha az aÄŸaÃ§
            max_depth=6,         # Daha sÄ±ÄŸ aÄŸaÃ§lar
            learning_rate=0.1,
            random_state=42
        )
        
        # Modeli eÄŸit
        gb_model.fit(X_train, y_train)
        
        # Tahmin yap
        y_pred = gb_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        logger.info(f"Gradient Boosting doÄŸruluk: {accuracy:.4f}")
        
        # Modeli kaydet
        model_path = 'models/gradient_boosting_model.pkl'
        with open(model_path, 'wb') as f:
            pickle.dump(gb_model, f)
        logger.info(f"Gradient Boosting modeli kaydedildi: {model_path}")
        
        return gb_model, accuracy
        
    except Exception as e:
        logger.error(f"Gradient Boosting eÄŸitim hatasÄ±: {e}")
        return None, 0

def create_ensemble_model(rf_model, gb_model, feature_columns):
    """Ensemble model oluÅŸtur"""
    logger.info("Ensemble model oluÅŸturuluyor...")
    
    try:
        ensemble = {
            'random_forest': rf_model,
            'gradient_boosting': gb_model,
            'feature_columns': feature_columns,
            'created_at': datetime.now().isoformat()
        }
        
        # Ensemble modeli kaydet
        ensemble_path = 'models/ensemble_model.pkl'
        with open(ensemble_path, 'wb') as f:
            pickle.dump(ensemble, f)
        logger.info(f"Ensemble model kaydedildi: {ensemble_path}")
        
        return ensemble
        
    except Exception as e:
        logger.error(f"Ensemble model oluÅŸturma hatasÄ±: {e}")
        return None

def main():
    """Ana eÄŸitim fonksiyonu"""
    logger.info("ğŸš€ HAFÄ°F AI MODEL EÄÄ°TÄ°MÄ° BAÅLATIYOR")
    
    try:
        # BelleÄŸi temizle
        gc.collect()
        
        # Veriyi hazÄ±rla
        data_result = prepare_training_data()
        if data_result is None:
            logger.error("Veri hazÄ±rlama baÅŸarÄ±sÄ±z")
            return False
        
        X_train, X_test, y_train, y_test, feature_columns = data_result
        
        # BelleÄŸi temizle
        gc.collect()
        
        # Random Forest eÄŸit
        rf_model, rf_accuracy = train_random_forest(X_train, X_test, y_train, y_test, feature_columns)
        
        # BelleÄŸi temizle
        gc.collect()
        
        # Gradient Boosting eÄŸit
        gb_model, gb_accuracy = train_gradient_boosting(X_train, X_test, y_train, y_test, feature_columns)
        
        # BelleÄŸi temizle
        gc.collect()
        
        # Ensemble model oluÅŸtur
        if rf_model is not None and gb_model is not None:
            ensemble = create_ensemble_model(rf_model, gb_model, feature_columns)
            
            # SonuÃ§ raporu
            logger.info("=" * 50)
            logger.info("ğŸ“Š EÄÄ°TÄ°M SONUÃ‡LARI")
            logger.info("=" * 50)
            logger.info(f"Random Forest DoÄŸruluk: {rf_accuracy:.4f}")
            logger.info(f"Gradient Boosting DoÄŸruluk: {gb_accuracy:.4f}")
            logger.info(f"Ortalama DoÄŸruluk: {(rf_accuracy + gb_accuracy) / 2:.4f}")
            logger.info("âœ… EÄŸitim baÅŸarÄ±yla tamamlandÄ±!")
            
            return True
        else:
            logger.error("Model eÄŸitimi baÅŸarÄ±sÄ±z")
            return False
            
    except Exception as e:
        logger.error(f"EÄŸitim hatasÄ±: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("âœ… Hafif eÄŸitim baÅŸarÄ±yla tamamlandÄ±!")
    else:
        print("âŒ EÄŸitim baÅŸarÄ±sÄ±z oldu!") 