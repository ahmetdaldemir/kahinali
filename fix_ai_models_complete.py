#!/usr/bin/env python3
"""
KapsamlÄ± AI Model DÃ¼zeltme Scripti
TÃ¼m AI model sorunlarÄ±nÄ± Ã§Ã¶zer ve sinyal kalitesini artÄ±rÄ±r
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import joblib
import logging
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_and_prepare_data():
    """Veri yÃ¼kle ve hazÄ±rla"""
    print("ğŸ“Š Veri yÃ¼kleniyor ve hazÄ±rlanÄ±yor...")
    
    try:
        # 6 aylÄ±k veriyi yÃ¼kle
        data_files = []
        data_dir = "data"
        
        for file in os.listdir(data_dir):
            if file.endswith('_6months.csv'):
                data_files.append(os.path.join(data_dir, file))
        
        print(f"ğŸ“ {len(data_files)} veri dosyasÄ± bulundu")
        
        all_data = []
        for file in data_files[:50]:  # Ä°lk 50 dosyayÄ± al (hÄ±z iÃ§in)
            try:
                df = pd.read_csv(file)
                if len(df) > 100:  # En az 100 satÄ±r olan dosyalarÄ± al
                    all_data.append(df)
            except Exception as e:
                logger.warning(f"Dosya yÃ¼klenemedi {file}: {e}")
                continue
        
        if not all_data:
            raise Exception("HiÃ§ veri yÃ¼klenemedi!")
        
        # Verileri birleÅŸtir
        combined_data = pd.concat(all_data, ignore_index=True)
        print(f"ğŸ“ˆ Toplam {len(combined_data)} satÄ±r veri yÃ¼klendi")
        
        # Veri temizleme
        combined_data = combined_data.dropna()
        combined_data = combined_data.replace([np.inf, -np.inf], np.nan)
        combined_data = combined_data.dropna()
        
        # AykÄ±rÄ± deÄŸerleri temizle
        for col in combined_data.select_dtypes(include=[np.number]).columns:
            Q1 = combined_data[col].quantile(0.25)
            Q3 = combined_data[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            combined_data = combined_data[(combined_data[col] >= lower_bound) & (combined_data[col] <= upper_bound)]
        
        print(f"ğŸ§¹ Temizlik sonrasÄ± {len(combined_data)} satÄ±r kaldÄ±")
        
        return combined_data
        
    except Exception as e:
        logger.error(f"Veri yÃ¼kleme hatasÄ±: {e}")
        return None

def create_advanced_features(df):
    """GeliÅŸmiÅŸ Ã¶zellikler oluÅŸtur"""
    print("ğŸ”§ GeliÅŸmiÅŸ Ã¶zellikler oluÅŸturuluyor...")
    
    try:
        # Teknik analiz Ã¶zellikleri
        df['price_change'] = df['close'].pct_change()
        df['volume_change'] = df['volume'].pct_change()
        
        # Hareketli ortalamalar
        for period in [5, 10, 20, 50]:
            df[f'sma_{period}'] = df['close'].rolling(window=period).mean()
            df[f'ema_{period}'] = df['close'].ewm(span=period).mean()
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # MACD
        ema12 = df['close'].ewm(span=12).mean()
        ema26 = df['close'].ewm(span=26).mean()
        df['macd'] = ema12 - ema26
        df['macd_signal'] = df['macd'].ewm(span=9).mean()
        df['macd_histogram'] = df['macd'] - df['macd_signal']
        
        # Bollinger Bands
        df['bb_middle'] = df['close'].rolling(window=20).mean()
        bb_std = df['close'].rolling(window=20).std()
        df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
        df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        
        # Volatilite
        df['volatility'] = df['close'].rolling(window=20).std()
        df['volatility_ratio'] = df['volatility'] / df['close']
        
        # Momentum
        df['momentum'] = df['close'] - df['close'].shift(10)
        df['momentum_ratio'] = df['momentum'] / df['close'].shift(10)
        
        # Hacim analizi
        df['volume_sma'] = df['volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma']
        
        # Fiyat pozisyonu
        df['price_position'] = (df['close'] - df['close'].rolling(window=50).min()) / (df['close'].rolling(window=50).max() - df['close'].rolling(window=50).min())
        
        # Trend gÃ¼cÃ¼
        df['trend_strength'] = abs(df['sma_20'] - df['sma_50']) / df['sma_50']
        
        # Support/Resistance
        df['support_level'] = df['close'].rolling(window=20).min()
        df['resistance_level'] = df['close'].rolling(window=20).max()
        df['support_distance'] = (df['close'] - df['support_level']) / df['close']
        df['resistance_distance'] = (df['resistance_level'] - df['close']) / df['close']
        
        # Zaman Ã¶zellikleri
        df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
        df['day_of_week'] = pd.to_datetime(df['timestamp']).dt.dayofweek
        
        # NaN deÄŸerleri temizle
        df = df.dropna()
        
        print(f"âœ… {len(df.columns)} Ã¶zellik oluÅŸturuldu")
        return df
        
    except Exception as e:
        logger.error(f"Ã–zellik oluÅŸturma hatasÄ±: {e}")
        return None

def create_target_variables(df):
    """Hedef deÄŸiÅŸkenler oluÅŸtur"""
    print("ğŸ¯ Hedef deÄŸiÅŸkenler oluÅŸturuluyor...")
    
    try:
        # Gelecek fiyat deÄŸiÅŸimleri
        for period in [1, 4, 8, 24]:  # 1h, 4h, 8h, 24h
            df[f'future_return_{period}h'] = df['close'].shift(-period) / df['close'] - 1
        
        # Volatilite hedefi
        df['future_volatility'] = df['close'].shift(-24).rolling(window=24).std() / df['close']
        
        # Trend hedefi
        df['future_trend'] = np.where(df['future_return_24h'] > 0.02, 1, 0)  # %2'den fazla artÄ±ÅŸ
        
        # Breakout hedefi
        df['future_breakout'] = np.where(df['future_return_8h'] > 0.05, 1, 0)  # %5'den fazla artÄ±ÅŸ
        
        # Risk/Ã–dÃ¼l hedefi
        df['future_risk_reward'] = df['future_return_8h'] / (df['future_return_1h'].abs() + 0.001)
        
        # NaN deÄŸerleri temizle
        df = df.dropna()
        
        print(f"âœ… {len([col for col in df.columns if 'future_' in col])} hedef deÄŸiÅŸken oluÅŸturuldu")
        return df
        
    except Exception as e:
        logger.error(f"Hedef deÄŸiÅŸken oluÅŸturma hatasÄ±: {e}")
        return None

def train_advanced_models(df):
    """GeliÅŸmiÅŸ modeller eÄŸit"""
    print("ğŸ¤– GeliÅŸmiÅŸ modeller eÄŸitiliyor...")
    
    try:
        # Ã–zellik sÃ¼tunlarÄ±
        feature_cols = [col for col in df.columns if col not in ['timestamp', 'symbol'] and not col.startswith('future_')]
        
        # Hedef deÄŸiÅŸkenler
        target_cols = [col for col in df.columns if col.startswith('future_')]
        
        print(f"ğŸ“Š {len(feature_cols)} Ã¶zellik, {len(target_cols)} hedef deÄŸiÅŸken")
        
        # Veriyi Ã¶lÃ§eklendir
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df[feature_cols])
        
        models = {}
        model_scores = {}
        
        # Her hedef iÃ§in model eÄŸit
        for target in target_cols:
            print(f"ğŸ¯ {target} iÃ§in model eÄŸitiliyor...")
            
            y = df[target]
            
            # Veriyi bÃ¶l
            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
            
            # Random Forest
            rf_model = RandomForestRegressor(
                n_estimators=200,
                max_depth=15,
                min_samples_split=10,
                min_samples_leaf=5,
                random_state=42,
                n_jobs=-1
            )
            
            # Gradient Boosting
            gb_model = GradientBoostingRegressor(
                n_estimators=200,
                max_depth=8,
                learning_rate=0.1,
                random_state=42
            )
            
            # Modelleri eÄŸit
            rf_model.fit(X_train, y_train)
            gb_model.fit(X_train, y_train)
            
            # SkorlarÄ± hesapla
            rf_score = rf_model.score(X_test, y_test)
            gb_score = gb_model.score(X_test, y_test)
            
            # En iyi modeli seÃ§
            if rf_score > gb_score:
                models[target] = rf_model
                model_scores[target] = rf_score
                print(f"   âœ… Random Forest seÃ§ildi (RÂ²: {rf_score:.4f})")
            else:
                models[target] = gb_model
                model_scores[target] = gb_score
                print(f"   âœ… Gradient Boosting seÃ§ildi (RÂ²: {gb_score:.4f})")
        
        # Ensemble model oluÅŸtur
        ensemble_model = {
            'models': models,
            'scaler': scaler,
            'feature_cols': feature_cols,
            'target_cols': target_cols,
            'scores': model_scores
        }
        
        print(f"âœ… {len(models)} model eÄŸitildi")
        print(f"ğŸ“ˆ Ortalama RÂ² skoru: {np.mean(list(model_scores.values())):.4f}")
        
        return ensemble_model
        
    except Exception as e:
        logger.error(f"Model eÄŸitme hatasÄ±: {e}")
        return None

def save_models(ensemble_model):
    """Modelleri kaydet"""
    print("ğŸ’¾ Modeller kaydediliyor...")
    
    try:
        # Models dizinini oluÅŸtur
        os.makedirs('models', exist_ok=True)
        
        # Ensemble modeli kaydet
        joblib.dump(ensemble_model, 'models/ensemble_model.pkl')
        
        # Ã–zellik sÃ¼tunlarÄ±nÄ± kaydet
        joblib.dump(ensemble_model['feature_cols'], 'models/feature_cols.pkl')
        
        # Scaler'Ä± kaydet
        joblib.dump(ensemble_model['scaler'], 'models/scaler.pkl')
        
        # Model performans raporu
        performance_report = {
            'training_date': datetime.now().isoformat(),
            'model_count': len(ensemble_model['models']),
            'feature_count': len(ensemble_model['feature_cols']),
            'average_score': np.mean(list(ensemble_model['scores'].values())),
            'individual_scores': ensemble_model['scores']
        }
        
        joblib.dump(performance_report, 'models/performance_report.pkl')
        
        print("âœ… Modeller baÅŸarÄ±yla kaydedildi")
        return True
        
    except Exception as e:
        logger.error(f"Model kaydetme hatasÄ±: {e}")
        return False

def test_models(ensemble_model):
    """Modelleri test et"""
    print("ğŸ§ª Modeller test ediliyor...")
    
    try:
        # Test verisi oluÅŸtur
        test_data = np.random.randn(100, len(ensemble_model['feature_cols']))
        test_data_scaled = ensemble_model['scaler'].transform(test_data)
        
        predictions = {}
        
        for target, model in ensemble_model['models'].items():
            pred = model.predict(test_data_scaled)
            predictions[target] = pred
        
        # AI skoru hesapla
        if 'future_return_8h' in predictions:
            returns = predictions['future_return_8h']
            ai_score = np.mean(np.where(returns > 0, returns, 0)) * 100
            print(f"ğŸ“Š Test AI skoru: {ai_score:.2f}")
        
        print("âœ… Model testi baÅŸarÄ±lÄ±")
        return True
        
    except Exception as e:
        logger.error(f"Model test hatasÄ±: {e}")
        return False

def main():
    """Ana fonksiyon"""
    print("ğŸš€ KAPSAMLI AI MODEL DÃœZELTME")
    print("=" * 50)
    print(f"BaÅŸlangÄ±Ã§ zamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. Veri yÃ¼kle
    df = load_and_prepare_data()
    if df is None:
        print("âŒ Veri yÃ¼kleme baÅŸarÄ±sÄ±z!")
        return
    
    # 2. Ã–zellikler oluÅŸtur
    df = create_advanced_features(df)
    if df is None:
        print("âŒ Ã–zellik oluÅŸturma baÅŸarÄ±sÄ±z!")
        return
    
    # 3. Hedef deÄŸiÅŸkenler oluÅŸtur
    df = create_target_variables(df)
    if df is None:
        print("âŒ Hedef deÄŸiÅŸken oluÅŸturma baÅŸarÄ±sÄ±z!")
        return
    
    # 4. Modelleri eÄŸit
    ensemble_model = train_advanced_models(df)
    if ensemble_model is None:
        print("âŒ Model eÄŸitme baÅŸarÄ±sÄ±z!")
        return
    
    # 5. Modelleri kaydet
    if not save_models(ensemble_model):
        print("âŒ Model kaydetme baÅŸarÄ±sÄ±z!")
        return
    
    # 6. Modelleri test et
    if not test_models(ensemble_model):
        print("âŒ Model testi baÅŸarÄ±sÄ±z!")
        return
    
    print()
    print("ğŸ‰ AI MODEL DÃœZELTME TAMAMLANDI!")
    print(f"BitiÅŸ zamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    print("ğŸ“Š SONUÃ‡LAR:")
    print(f"   - {len(ensemble_model['models'])} model eÄŸitildi")
    print(f"   - {len(ensemble_model['feature_cols'])} Ã¶zellik kullanÄ±ldÄ±")
    print(f"   - Ortalama RÂ² skoru: {np.mean(list(ensemble_model['scores'].values())):.4f}")
    print()
    print("ğŸ’¡ Sistem artÄ±k daha yÃ¼ksek kaliteli sinyaller Ã¼retecek!")

if __name__ == "__main__":
    main() 